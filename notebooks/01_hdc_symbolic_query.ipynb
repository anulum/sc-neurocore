{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDC Symbolic Query Demo \u2014 \"Capital of France?\"\n",
    "\n",
    "**SC-NeuroCore v3.7 \u2014 Hyper-Dimensional Computing (HDC/VSA) Kernel**\n",
    "\n",
    "This notebook demonstrates how SC-NeuroCore's SIMD-accelerated `BitStreamTensor` enables\n",
    "symbolic reasoning via Hyper-Dimensional Computing on 10,000-bit binary vectors.\n",
    "\n",
    "**Key operations:**\n",
    "- **Bind** (`*` / XOR) \u2014 associates two concepts (self-inverse)\n",
    "- **Bundle** (`+` / majority vote) \u2014 combines multiple items into a set\n",
    "- **Permute** (cyclic rotation) \u2014 encodes position/sequence\n",
    "- **Similarity** (1 \u2212 normalised Hamming distance) \u2014 measures relatedness\n",
    "\n",
    "> CopyRight: (c) 1998-2026 Miroslav Sotek. All rights reserved.  \n",
    "> License: GNU AFFERO GENERAL PUBLIC LICENSE v3 | Commercial Licensing Available  \n",
    "> Contact: www.anulum.li \u00a0 protoscience@anulum.li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_neurocore_engine import HDCVector\n",
    "\n",
    "DIM = 10_000  # 10,000-bit hypervectors\n",
    "print(f\"SC-NeuroCore HDC Symbolic Query Demo (D={DIM})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Atomic Symbols\n",
    "\n",
    "Each concept (country, capital, role) gets a random 10,000-bit vector.\n",
    "Random high-dimensional vectors are quasi-orthogonal: pairwise similarity \u2248 0.50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Role vectors\n",
    "role_country = HDCVector(DIM, seed=1000)\n",
    "role_capital = HDCVector(DIM, seed=1001)\n",
    "\n",
    "# Country atoms\n",
    "france  = HDCVector(DIM, seed=2000)\n",
    "germany = HDCVector(DIM, seed=2001)\n",
    "japan   = HDCVector(DIM, seed=2002)\n",
    "\n",
    "# Capital atoms\n",
    "paris  = HDCVector(DIM, seed=3000)\n",
    "berlin = HDCVector(DIM, seed=3001)\n",
    "tokyo  = HDCVector(DIM, seed=3002)\n",
    "\n",
    "atoms = {\n",
    "    \"France\": france, \"Germany\": germany, \"Japan\": japan,\n",
    "    \"Paris\": paris, \"Berlin\": berlin, \"Tokyo\": tokyo,\n",
    "}\n",
    "\n",
    "print(f\"Pairwise similarity (should be ~0.50):\")\n",
    "print(f\"  France vs Germany: {france.similarity(germany):.3f}\")\n",
    "print(f\"  Paris vs Berlin:   {paris.similarity(berlin):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Encode Records\n",
    "\n",
    "Each country\u2013capital pair is encoded as:\n",
    "\n",
    "$$\\text{record} = (\\text{role\\_country} \\oplus \\text{country}) + (\\text{role\\_capital} \\oplus \\text{capital})$$\n",
    "\n",
    "where $\\oplus$ is XOR-bind and $+$ is majority-vote bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_france  = HDCVector.bundle([role_country * france,  role_capital * paris])\n",
    "rec_germany = HDCVector.bundle([role_country * germany, role_capital * berlin])\n",
    "rec_japan   = HDCVector.bundle([role_country * japan,   role_capital * tokyo])\n",
    "\n",
    "# Bundle all records into memory\n",
    "memory = HDCVector.bundle([rec_france, rec_germany, rec_japan])\n",
    "print(\"Records encoded and bundled into memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Query \u2014 \"Which countries are in memory?\"\n",
    "\n",
    "Unbind the capital role from memory to reveal country associations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = memory * role_capital\n",
    "\n",
    "print(\"Query: 'Which countries are in memory?' (unbind role_capital)\")\n",
    "for name, atom in [(\"France\", france), (\"Germany\", germany),\n",
    "                   (\"Japan\", japan), (\"Paris\", paris)]:\n",
    "    sim = probe.similarity(atom)\n",
    "    print(f\"  sim(probe, {name:>8s}) = {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Query \u2014 \"Capital of France?\"\n",
    "\n",
    "Two-step unbinding:\n",
    "1. Unbind France from memory: `hat = memory * france`\n",
    "2. Unbind the capital role: `answer = hat * role_capital`\n",
    "\n",
    "The result should be most similar to **Paris**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat = memory * france\n",
    "answer = hat * role_capital\n",
    "\n",
    "print(\"Query: 'Capital of France?' (memory * France * role_capital)\")\n",
    "best_name, best_sim = \"\", -1.0\n",
    "for name, atom in atoms.items():\n",
    "    sim = answer.similarity(atom)\n",
    "    if sim > best_sim:\n",
    "        best_sim = sim\n",
    "        best_name = name\n",
    "    print(f\"  sim(answer, {name:>8s}) = {sim:.4f}\")\n",
    "\n",
    "print(f\"\\nBest match: {best_name} (similarity {best_sim:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Bind-Inverse Property\n",
    "\n",
    "XOR is self-inverse: $(a \\oplus b) \\oplus b = a$. This is the mathematical foundation\n",
    "that makes unbinding work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = HDCVector(DIM, seed=42)\n",
    "b = HDCVector(DIM, seed=99)\n",
    "recovered = (a * b) * b\n",
    "sim = recovered.similarity(a)\n",
    "print(f\"Bind-inverse: sim(a, (a*b)*b) = {sim:.4f} (should be ~1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Permute for Sequence Encoding\n",
    "\n",
    "Cyclic rotation produces quasi-orthogonal vectors, enabling position encoding:\n",
    "\n",
    "$$\\text{sim}(v, \\pi^k(v)) \\approx 0.50 \\quad \\text{for } k \\neq 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v  = HDCVector(DIM, seed=42)\n",
    "p1 = v.permute(1)\n",
    "p2 = v.permute(2)\n",
    "print(f\"Permute orthogonality:\")\n",
    "print(f\"  sim(v, permute(v,1)) = {v.similarity(p1):.4f}\")\n",
    "print(f\"  sim(v, permute(v,2)) = {v.similarity(p2):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
